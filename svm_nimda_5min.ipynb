{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BGP Anomaly Detection using SVM\n",
    "\n",
    "This notebook explores how to use Support Vector Machines (SVM) for detecting BGP routing anomalies using the feature-rich datasets extracted by the BGP Feature Extractor tool.\n",
    "\n",
    "## What is BGP?\n",
    "\n",
    "Border Gateway Protocol (BGP) is the routing protocol that enables the global internet to function by allowing autonomous systems (ASes) to exchange network reachability information. BGP anomalies can include route hijacks, leaks, configuration errors, or infrastructure failures that disrupt normal internet routing.\n",
    "\n",
    "## What are we doing in this notebook?\n",
    "\n",
    "1. Load and explore labeled BGP features from a dataset\n",
    "2. Preprocess the data for machine learning\n",
    "3. Train an SVM model to detect anomalies\n",
    "4. Evaluate the model's performance using ROC curves, precision-recall curves, etc.\n",
    "5. Explain model predictions using SHAP and LIME\n",
    "6. Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install shap\n",
    "!pip install lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, accuracy_score, \n",
    "    precision_recall_fscore_support, roc_curve, auc, \n",
    "    precision_recall_curve, average_precision_score\n",
    ")\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Import explainability libraries if installed\n",
    "try:\n",
    "    import shap\n",
    "    import lime\n",
    "    import lime.lime_tabular\n",
    "    EXPLAINABILITY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    EXPLAINABILITY_AVAILABLE = False\n",
    "    print(\"Warning: SHAP and/or LIME libraries not installed. Explainability sections will be skipped.\")\n",
    "    print(\"Run 'pip install shap lime' to install them.\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the Dataset\n",
    "\n",
    "We'll load a dataset that contains BGP features extracted from an anomaly event. For this example, we'll use a dataset from the Code Red worm incident, which caused significant routing disruption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset - update the path to the dataset file you want to use\n",
    "dataset_path = \"datasets/ratios/dataset_nimda_513_5_rrc04.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "# Check the first few rows\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic statistics\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in each column:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with 0 (if any)\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check class distribution\n",
    "print(\"Class distribution:\")\n",
    "print(df['class'].value_counts())\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='class', data=df)\n",
    "plt.title('Class Distribution (0 = Normal, 1 = Anomaly)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop non-feature columns\n",
    "columns_to_drop = ['timestamp', 'timestamp2', 'Unnamed: 0']\n",
    "for col in columns_to_drop:\n",
    "    if col in df.columns:\n",
    "        df = df.drop(col, axis=1)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "\n",
    "# Display feature names\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(\"Feature names:\")\n",
    "X.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Analysis and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance for anomaly detection\n",
    "# For each feature, calculate the mean difference between normal and anomaly periods\n",
    "anomaly = df[df['class'] == 1]\n",
    "normal = df[df['class'] == 0]\n",
    "\n",
    "# Calculate mean differences\n",
    "feature_diffs = {}\n",
    "for col in X.columns:\n",
    "    if col != 'class':\n",
    "        normal_mean = normal[col].mean()\n",
    "        anomaly_mean = anomaly[col].mean() if not anomaly.empty else 0\n",
    "        \n",
    "        # Prevent division by zero\n",
    "        if normal_mean == 0:\n",
    "            if anomaly_mean == 0:\n",
    "                diff = 0\n",
    "            else:\n",
    "                diff = float('inf')\n",
    "        else:\n",
    "            diff = (anomaly_mean - normal_mean) / normal_mean\n",
    "        \n",
    "        feature_diffs[col] = diff\n",
    "\n",
    "# Convert to DataFrame for better visualization\n",
    "feature_diff_df = pd.DataFrame(list(feature_diffs.items()), columns=['Feature', 'Relative Change'])\n",
    "feature_diff_df = feature_diff_df.sort_values('Relative Change', key=abs, ascending=False)\n",
    "\n",
    "# Plot top features by absolute difference\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(x='Relative Change', y='Feature', data=feature_diff_df.head(15))\n",
    "plt.title('Top 15 Features by Absolute Relative Change Between Normal and Anomaly Periods')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top features based on difference analysis\n",
    "top_features = feature_diff_df.head(15)['Feature'].tolist()\n",
    "print(\"Selected top features:\")\n",
    "print(top_features)\n",
    "\n",
    "# Extract selected features from dataset\n",
    "X_selected = X[top_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape}\")\n",
    "print(f\"Testing set size: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. SVM Model Training and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with preprocessing and SVM\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(probability=True))\n",
    "])\n",
    "\n",
    "# Define the hyperparameter search space\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "    'svm__kernel': ['rbf', 'linear', 'poly']\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='f1', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print best parameters\n",
    "print(\"Best parameters found:\")\n",
    "print(grid_search.best_params_)\n",
    "print(f\"Best CV score: {grid_search.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate on test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]  # Probability of the positive class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Evaluation with Advanced Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['Normal', 'Anomaly'],\n",
    "            yticklabels=['Normal', 'Anomaly'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot ROC curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and plot Precision-Recall curve\n",
    "precision_values, recall_values, _ = precision_recall_curve(y_test, y_proba)\n",
    "avg_precision = average_precision_score(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(recall_values, precision_values, color='blue', lw=2, \n",
    "         label=f'Precision-Recall curve (AP = {avg_precision:.2f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing Decision Boundaries\n",
    "\n",
    "Let's use PCA to reduce our features to 2 dimensions and visualize the SVM decision boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to reduce to 2 dimensions for visualization\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_selected)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Explained variance\n",
    "print(f\"Explained variance ratio: {pca.explained_variance_ratio_}\")\n",
    "print(f\"Total explained variance: {sum(pca.explained_variance_ratio_):.2f}\")\n",
    "\n",
    "# Create a DataFrame for easier plotting\n",
    "pca_df = pd.DataFrame(data=X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['class'] = y.values\n",
    "\n",
    "# Plot PCA results\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='class', data=pca_df, palette='Set1', s=100, alpha=0.7)\n",
    "plt.title('PCA of BGP Features (2 Components)')\n",
    "plt.legend(title='Class', labels=['Normal', 'Anomaly'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train an SVM on the PCA-transformed data\n",
    "X_train_pca, X_test_pca, y_train_pca, y_test_pca = train_test_split(\n",
    "    X_pca, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Use best parameters from grid search but adapt to the 2D case\n",
    "best_params = grid_search.best_params_\n",
    "svm_2d = SVC(\n",
    "    C=best_params['svm__C'],\n",
    "    gamma=best_params['svm__gamma'] if best_params['svm__gamma'] not in ['scale', 'auto'] else 'scale',\n",
    "    kernel=best_params['svm__kernel'],\n",
    "    probability=True\n",
    ")\n",
    "svm_2d.fit(X_train_pca, y_train_pca)\n",
    "\n",
    "# Plot decision boundary\n",
    "def plot_decision_boundary(X, y, model, ax=None):\n",
    "    h = 0.02  # Step size in the mesh\n",
    "    \n",
    "    # Create mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    \n",
    "    # Get predictions for each point in the mesh\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    if ax is None:\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        ax = plt.gca()\n",
    "    \n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='coolwarm')\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='coolwarm', s=100, alpha=0.7, edgecolors='k')\n",
    "    return ax\n",
    "\n",
    "plt.figure(figsize=(14, 12))\n",
    "ax = plot_decision_boundary(X_pca, y.values, svm_2d)\n",
    "plt.title(f'SVM Decision Boundary (Kernel: {best_params[\"svm__kernel\"]})')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Anomaly Score Time Series\n",
    "\n",
    "We can plot the prediction probabilities (anomaly scores) as a time series to see how the model's confidence varies over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset again to get timestamps\n",
    "full_df = pd.read_csv(dataset_path)\n",
    "timestamps = full_df['timestamp']\n",
    "\n",
    "# Predict probabilities on all data\n",
    "X_all_selected = X_selected.copy()\n",
    "all_proba = best_model.predict_proba(X_all_selected)[:, 1]\n",
    "\n",
    "# Create time series dataframe\n",
    "time_series_df = pd.DataFrame({\n",
    "    'timestamp': timestamps,\n",
    "    'anomaly_score': all_proba,\n",
    "    'true_class': y\n",
    "})\n",
    "\n",
    "# Convert timestamp strings to datetime objects if not already\n",
    "time_series_df['timestamp'] = pd.to_datetime(time_series_df['timestamp'])\n",
    "\n",
    "# Plot anomaly score time series\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(time_series_df['timestamp'], time_series_df['anomaly_score'], 'b-', label='Anomaly Score')\n",
    "\n",
    "# Highlight actual anomaly periods\n",
    "anomaly_periods = time_series_df[time_series_df['true_class'] == 1]\n",
    "for idx, row in anomaly_periods.iterrows():\n",
    "    plt.axvline(x=row['timestamp'], color='r', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Add horizontal line at threshold 0.5\n",
    "plt.axhline(y=0.5, color='g', linestyle='-', label='Decision Threshold')\n",
    "\n",
    "plt.title('BGP Anomaly Detection Time Series')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Anomaly Score (Probability)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis with Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a linear SVM for feature importance analysis\n",
    "linear_svm = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svm', SVC(kernel='linear'))\n",
    "])\n",
    "linear_svm.fit(X_train, y_train)\n",
    "\n",
    "# Extract feature importance scores (coefficients)\n",
    "importances = abs(linear_svm.named_steps['svm'].coef_[0])\n",
    "feature_importance = pd.DataFrame({'Feature': X_selected.columns, 'Importance': importances})\n",
    "feature_importance = feature_importance.sort_values('Importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance)\n",
    "plt.title('Feature Importance (Linear SVM Coefficients)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. SHAP Values for Model Explainability\n",
    "\n",
    "SHAP (SHapley Additive exPlanations) values allow us to understand how each feature contributes to individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLAINABILITY_AVAILABLE:\n",
    "    # Create a simpler model for SHAP analysis (to speed up computation)\n",
    "    shap_model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(kernel='linear', probability=True))\n",
    "    ])\n",
    "    shap_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Use a subset of training data as background for the explainer\n",
    "    X_train_sample = X_train.sample(min(100, len(X_train)), random_state=42)\n",
    "    X_train_transformed = shap_model.named_steps['scaler'].transform(X_train_sample)\n",
    "    \n",
    "    # Create a SHAP KernelExplainer\n",
    "    def f(x):\n",
    "        return shap_model.predict_proba(x)[:,1]\n",
    "    \n",
    "    explainer = shap.KernelExplainer(f, X_train_transformed)\n",
    "    \n",
    "    # Select a sample of test instances to explain\n",
    "    X_test_sample = X_test.sample(min(10, len(X_test)), random_state=42)\n",
    "    X_test_transformed = shap_model.named_steps['scaler'].transform(X_test_sample)\n",
    "    \n",
    "    # Compute SHAP values\n",
    "    shap_values = explainer.shap_values(X_test_transformed)\n",
    "    \n",
    "    # Summary plot\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X_test_sample, feature_names=X_selected.columns)\n",
    "    \n",
    "    # SHAP dependence plot for top feature\n",
    "    top_feature_idx = np.argmax(np.abs(explainer.expected_value))\n",
    "    top_feature = X_selected.columns[top_feature_idx]\n",
    "    \n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.dependence_plot(top_feature_idx, shap_values, X_test_transformed, \n",
    "                         feature_names=X_selected.columns)\n",
    "else:\n",
    "    print(\"SHAP analysis skipped because libraries are not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. LIME for Local Interpretability\n",
    "\n",
    "LIME (Local Interpretable Model-agnostic Explanations) helps understand what features are most important for a specific prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPLAINABILITY_AVAILABLE:\n",
    "    # Create a LIME explainer\n",
    "    lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train.values,\n",
    "        feature_names=X_selected.columns.tolist(),\n",
    "        class_names=['Normal', 'Anomaly'],\n",
    "        verbose=True,\n",
    "        mode='classification'\n",
    "    )\n",
    "    \n",
    "    # Find an anomaly instance to explain\n",
    "    anomaly_indices = np.where(y_test == 1)[0]\n",
    "    if len(anomaly_indices) > 0:\n",
    "        # Pick an anomaly in the test set\n",
    "        anomaly_idx = anomaly_indices[0]\n",
    "        anomaly_instance = X_test.iloc[anomaly_idx].values\n",
    "        \n",
    "        # Generate LIME explanation\n",
    "        lime_exp = lime_explainer.explain_instance(\n",
    "            anomaly_instance, \n",
    "            best_model.predict_proba,\n",
    "            num_features=10\n",
    "        )\n",
    "        \n",
    "        # Plot the explanation\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        lime_exp.as_pyplot_figure()\n",
    "        plt.title(\"LIME Explanation for Anomaly Instance\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No anomalies found in test set\")\n",
    "else:\n",
    "    print(\"LIME analysis skipped because libraries are not installed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Persistence\n",
    "\n",
    "Save the trained model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(best_model, 'svm_nimda_5min_model.pkl')\n",
    "print(\"Model saved to 'bgp_anomaly_svm_model.pkl'\")\n",
    "\n",
    "# Save the feature list\n",
    "pd.DataFrame(top_features, columns=['Feature']).to_csv('nimda_5_bgp_anomaly_selected_features.csv', index=False)\n",
    "print(\"Selected features saved to 'bgp_anomaly_selected_features.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Loading the Model for Future Predictions\n",
    "\n",
    "Here's how you would load the model and make predictions on new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to load and use the model\n",
    "loaded_model = joblib.load('svm_nimda_5min_model.pkl')\n",
    "selected_features = pd.read_csv('nimda_5_bgp_anomaly_selected_features.csv')['Feature'].tolist()\n",
    "\n",
    "# Example with new data (replace with actual new data)\n",
    "# new_data = pd.read_csv('new_bgp_data.csv')\n",
    "# X_new = new_data[selected_features]\n",
    "# predictions = loaded_model.predict(X_new)\n",
    "# anomaly_scores = loaded_model.predict_proba(X_new)[:, 1]\n",
    "\n",
    "print(\"Model and feature list loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Conclusion\n",
    "\n",
    "In this notebook, we've built an SVM-based anomaly detection system for BGP routing data with comprehensive evaluation and explanations. The model can effectively distinguish between normal BGP traffic and anomalous events based on the features extracted by the BGP Feature Extractor tool.\n",
    "\n",
    "Key observations:\n",
    "1. Feature selection is crucial - we identified the most discriminative features\n",
    "2. SVM with appropriate hyperparameters can achieve high accuracy in detecting anomalies\n",
    "3. ROC curves and precision-recall curves provide deeper insights into model performance\n",
    "4. SHAP and LIME explain what features contribute most to anomaly predictions\n",
    "5. Visualizing the time series of anomaly scores helps understand model behavior over time\n",
    "\n",
    "This model could be deployed as part of a network monitoring system to provide early warning of potential BGP anomalies, helping to secure internet routing infrastructure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
